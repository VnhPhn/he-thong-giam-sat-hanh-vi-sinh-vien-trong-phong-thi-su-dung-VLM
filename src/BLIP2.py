import cv2
import torch
import numpy as np
from ultralytics import YOLO
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
import gradio as gr
import threading
import time
import os

# ========================
# ‚öôÔ∏è C·∫§U H√åNH
# ========================
CAM_URL = "http://172.16.31.141:4747/video"   # üëâ Thay IP ƒëi·ªán tho·∫°i IP Webcam c·ªßa b·∫°n
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LOG_DIR = "logs/evidence"
os.makedirs(LOG_DIR, exist_ok=True)

print(f"üß† Thi·∫øt b·ªã: {DEVICE}")

# ========================
# üîπ T·∫¢I M√î H√åNH
# ========================
print("üîπ ƒêang t·∫£i YOLO...")
yolo = YOLO(r"runs\detect\train_rtx3050\weights\best.pt")  # ƒê∆∞·ªùng d·∫´n model YOLO c·ªßa b·∫°n
print("‚úÖ YOLO s·∫µn s√†ng.")

print("üîπ ƒêang t·∫£i BLIP-2 Flan-T5-XL")
blip_proc = Blip2Processor.from_pretrained("Salesforce/blip2-flan-t5-xl")
blip_model = Blip2ForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-flan-t5-xl",
    torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32,
).to(DEVICE)
print("‚úÖ BLIP-2 Flan-T5-XL s·∫µn s√†ng.")

# ========================
# üß† H√ÄM PH√ÇN T√çCH ·∫¢NH
# ========================
def analyze_frame(frame, question):
    """Ph√¢n t√≠ch frame v√† tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng YOLO + BLIP-2 Flan-T5-XL."""
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = yolo.predict(source=rgb_frame, conf=0.15, verbose=False)[0]

    h, w, _ = frame.shape
    cheat_boxes = []
    cheat_index = 1

    for box in results.boxes:
        cls = int(box.cls[0])
        label = yolo.names.get(cls, str(cls))
        conf = float(box.conf[0])
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        pos_x = "b√™n tr√°i" if cx < w / 3 else "gi·ªØa" if cx < 2 * w / 3 else "b√™n ph·∫£i"
        pos_y = "h√†ng ƒë·∫ßu" if cy < h / 3 else "h√†ng gi·ªØa" if cy < 2 * h / 3 else "h√†ng sau"

        if label == "cheating":
            color = (0, 0, 255)
            tag = f"cheating-{cheat_index}"
            cheat_boxes.append((pos_x, pos_y, tag, conf))
            cheat_index += 1
        else:
            color = (0, 255, 0)
            tag = "non-cheating"

        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(frame, f"{tag} ({conf:.2f})", (x1, y1 - 8),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    # -------------------
    # 1Ô∏è‚É£ N·∫øu h·ªèi v·ªÅ gian l·∫≠n
    # -------------------
    lower_q = question.lower()
    if any(k in lower_q for k in ["gian l·∫≠n", "cheat", "ƒëi·ªán tho·∫°i", "phone"]):
        if not cheat_boxes:
            return "Kh√¥ng c√≥ ai gian l·∫≠n ho·∫∑c d√πng ƒëi·ªán tho·∫°i."
        else:
            descs = [f"{i+1}. {tag} ({conf:.2f}) ·ªü {y} {x}."
                     for i, (x, y, tag, conf) in enumerate(cheat_boxes)]
            answer = f"üö® C√≥ {len(cheat_boxes)} ng∆∞·ªùi ƒëang gian l·∫≠n:\n" + "\n".join(descs)

            timestamp = time.strftime("%Y%m%d-%H%M%S")
            save_path = os.path.join(LOG_DIR, f"cheating_{timestamp}.jpg")
            cv2.imwrite(save_path, frame)
            print(f"üì∏ ·∫¢nh b·∫±ng ch·ª©ng ƒë√£ l∆∞u: {save_path}")
            return answer

    # -------------------
    # 2Ô∏è‚É£ C√¢u h·ªèi kh√°c ‚Üí BLIP-2 Flan-T5-XL
    # -------------------
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    inputs = blip_proc(images=img_pil, text=question, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        out = blip_model.generate(**inputs, max_new_tokens=40)
    answer = blip_proc.tokenizer.decode(out[0], skip_special_tokens=True)

    torch.cuda.empty_cache()
    return answer


# ========================
# üí¨ CHAT GRADIO
# ========================
def chat_with_vlm(message, history):
    global current_frame
    if current_frame is None:
        return {"role": "assistant", "content": "‚ö†Ô∏è Ch∆∞a c√≥ khung h√¨nh camera."}
    answer = analyze_frame(current_frame.copy(), message)
    return {"role": "assistant", "content": f"üß† {answer}"}


# ========================
# üé• LU·ªíNG CAMERA OPENCV
# ========================
current_frame = None

def camera_loop():
    global current_frame
    cap = cv2.VideoCapture(CAM_URL)
    if not cap.isOpened():
        print("‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi camera. Ki·ªÉm tra l·∫°i IP Webcam.")
        return

    print("üì∑ Camera ƒë√£ k·∫øt n·ªëi th√†nh c√¥ng!")
    while True:
        ret, frame = cap.read()
        if not ret:
            continue
        current_frame = frame.copy()
        cv2.imshow("üì° Lu·ªìng camera realtime (Nh·∫•n Q ƒë·ªÉ tho√°t)", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


# ========================
# üåê GIAO DI·ªÜN GRADIO
# ========================
with gr.Blocks(theme="soft") as demo:
    gr.Markdown("## ü§ñ AI Gi√°m s√°t thi c·ª≠ (YOLOv8 + BLIP-2 Flan-T5-XL)")
    gr.Markdown("Camera realtime hi·ªÉn th·ªã qua OpenCV ‚Äî ƒë·∫∑t c√¢u h·ªèi cho AI t·∫°i ƒë√¢y üëá")

    chatbot = gr.ChatInterface(
        fn=chat_with_vlm,
        title="AI Gi√°m s√°t thi c·ª≠",
        textbox=gr.Textbox(placeholder="Nh·∫≠p c√¢u h·ªèi: Ai ƒëang gian l·∫≠n?..."),
        type="messages",
    )

# ========================
# üöÄ CH·∫†Y SONG SONG
# ========================
if __name__ == "__main__":
    threading.Thread(target=camera_loop, daemon=True).start()
    demo.launch(share=False)
